# ğŸ’» AI Coding Assistant (RAG + LangChain + OpenAI)

## ğŸ“˜ Overview

This project is an **AI-powered coding assistant** built using **LangChain**, **OpenAI GPT**, and **FAISS**.
It uses **Retrieval-Augmented Generation (RAG)** to answer programming and debugging-related questions.

Instead of relying solely on the modelâ€™s internal knowledge, it retrieves relevant information from a **local knowledge base** â€” containing documents like `debugging_guide.md` and `python_tips.txt` â€” and combines it with GPT reasoning to produce accurate, context-aware answers.

---

## ğŸ§  Features

* ğŸ§© **Retrieval-Augmented Generation (RAG)** pipeline using LangChain
* ğŸ§  **Custom Knowledge Base**: stored locally in `data/knowledge_base/`
* ğŸ’¬ **ChatGPT-style Interface** built with Streamlit
* âš™ï¸ **OpenAI API Integration** for high-quality responses
* ğŸ”’ Secure configuration via `.env` file (API keys are never exposed)

---

## ğŸ§© Project Structure

```
rag_coding_assistant/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui_streamlit.py      # Streamlit-based chat UI
â”‚   â”œâ”€â”€ rag_chain.py         # Defines the RAG pipeline (Retriever + LLM)
â”‚   â”œâ”€â”€ vectorstore.py       # Builds and loads FAISS vector database
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ knowledge_base/
â”‚       â”œâ”€â”€ debugging_guide.md   # Troubleshooting & debugging tips
â”‚       â”œâ”€â”€ python_tips.txt      # Python tricks and common pitfalls
â”‚
â”œâ”€â”€ .env                    # Stores API keys (not uploaded to GitHub)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ§° Tech Stack

| Component         | Technology         |
| ----------------- | ------------------ |
| Framework         | LangChain          |
| LLM Backend       | OpenAI GPT-4o-mini |
| Vector Store      | FAISS              |
| UI                | Streamlit          |
| Environment       | Python 3.10+       |
| Config Management | python-dotenv      |

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/rag_coding_assistant.git
cd rag_coding_assistant
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set Up Environment Variables

Create a `.env` file in your project root:

```bash
OPENAI_API_KEY=sk-your-openai-api-key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your-langsmith-api-key
LANGCHAIN_PROJECT=llm-chatbot
```

> âš ï¸ Never commit your `.env` file to GitHub.

---

## ğŸ§  Knowledge Base

The folder `data/knowledge_base/` contains reference material for the chatbot to retrieve answers from.

| File                 | Purpose                                                                     |
| -------------------- | --------------------------------------------------------------------------- |
| `debugging_guide.md` | Contains practical tips for debugging Python code.                          |
| `python_tips.txt`    | Includes common Python coding tricks, best practices, and syntax reminders. |

You can **add more `.txt` or `.md` files** here to expand your assistantâ€™s knowledge.

---

## ğŸ§© Script Descriptions

### `app/vectorstore.py`

* Loads all text/markdown files from `data/knowledge_base/`
* Splits documents into smaller chunks for embedding
* Uses `OpenAIEmbeddings()` to create vector representations
* Stores embeddings locally in a **FAISS** index
* Run this once to build the vectorstore:

  ```bash
  python -m app.vectorstore
  ```

---

### `app/rag_chain.py`

* Loads the FAISS vectorstore and wraps it in a retriever
* Initializes the OpenAI LLM (`gpt-4o-mini`)
* Combines retrieval and generation via `RetrievalQA`
* Acts as the **core logic** for the chatbotâ€™s reasoning

---

### `app/ui_streamlit.py`

* Provides an **interactive web UI** (similar to ChatGPT)
* Maintains chat history using Streamlit session state
* Sends user queries to the RAG chain and displays answers
* Run this to start the chatbot:

  ```bash
  streamlit run app/ui_streamlit.py
  ```

---

## ğŸ§© How It Works

1. You type a coding or debugging question in the chat.
2. The app retrieves relevant text chunks from your `knowledge_base` using FAISS.
3. The retrieved context is passed to the OpenAI GPT model.
4. The model generates an accurate, context-aware response.

```
User Question
     â†“
Vectorstore Retriever (FAISS)
     â†“
LangChain RAG (Retriever + LLM)
     â†“
OpenAI GPT Response
     â†“
Streamlit Chat UI
```

---

## ğŸ§ª Example Queries

You can try:

```
> How do I fix a syntax error in Python?
> What are some debugging best practices?
> Show me how to create a Python function that reverses a string.
> How do I handle exceptions in Python?
```

---

## ğŸ”’ Environment Variables

| Variable               | Description                                  |
| ---------------------- | -------------------------------------------- |
| `OPENAI_API_KEY`       | Your OpenAI API key                          |
| `LANGCHAIN_API_KEY`    | API key for LangSmith (optional for tracing) |
| `LANGCHAIN_TRACING_V2` | Enable tracing of LangChain runs             |
| `LANGCHAIN_PROJECT`    | Project name for LangSmith dashboard         |

---

Would you like me to generate a **short GitHub â€œAboutâ€ description (1â€“2 lines)** for your repo page â€” the one that appears at the top under your project title?
It makes your repo look polished and professional.
